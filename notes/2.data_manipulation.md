# Data Manipulation in Deep Learning

## Objectives

- Understand arrays and tensors.
- Learn common operations: addition, multiplication, reshaping, broadcasting.
- Explore how these concepts apply to deep learning workflows.

## Prerequisites

1. Install `numpy`
2. Install [`pytorch`](https://pytorch.org/get-started/locally/)
3. Install `matplotlib`

## Arrays vs. Tensors

### Definition
- **Arrays**: Multidimensional data structures provided by NumPy, used for numerical computations.
- **Tensors**: Generalization of arrays used in deep learning frameworks like PyTorch and TensorFlow. Tensors can be thought of as multi-dimensional arrays with additional capabilities.

### Similarities
- Both arrays and tensors can represent multi-dimensional data.
- Both support a wide range of mathematical operations.
- Both can be indexed and sliced in similar ways.

### Differences
- **Library**: Arrays are primarily used in NumPy, while tensors are used in deep learning frameworks like PyTorch and TensorFlow.
- **GPU Acceleration**: Tensors can leverage GPU acceleration for faster computations, which is crucial for deep learning tasks.
- **Autograd Functionality**: Tensors support automatic differentiation, which is essential for training neural networks. This means that tensors can automatically compute gradients, which are used in optimization algorithms like backpropagation.
- **Data Types**: While both arrays and tensors support various data types, tensors often have additional data types optimized for deep learning.

## Creating Arrays and Tensors

### How to Create Arrays/Tensors
- Zeros, ones, random initialization.
- Specifying data types.

### Example Code Snippet
```python
import numpy as np
import torch

# NumPy
np_array = np.zeros((3, 3))
print(np_array)

# PyTorch
torch_tensor = torch.zeros((3, 3))
print(torch_tensor)
```

## Common Operations
Operations overview:
- Element-wise addition.
- Dot product and matrix multiplication.

## Broadcasting
Concept:
Automatically aligning dimensions of arrays/tensors with different shapes.

Broadcasting allows NumPy and PyTorch to perform element-wise operations on arrays/tensors of different shapes by automatically expanding their dimensions to match each other. This is particularly useful for operations between a lower-dimensional array/tensor and a higher-dimensional one.

Rules for broadcasting:
1. If the arrays/tensors have different numbers of dimensions, the shape of the smaller-dimensional array/tensor is padded with ones on its left side.
2. If the shape of the arrays/tensors does not match in any dimension, the array/tensor with the shape equal to 1 in that dimension is stretched to match the other shape.
3. If in any dimension the sizes disagree and neither is equal to 1, an error is raised.

Example:
A 1D array being added to a 2D array.
```python
import numpy as np

a = np.array([[1, 2, 3], [4, 5, 6]])
b = np.array([10, 20, 30])
print(a + b)  # Broadcasting happens here
```

Similarly, in PyTorch, you can perform broadcasting.

```python
import torch

a = torch.tensor([[1, 2, 3], [4, 5, 6]])
b = torch.tensor([10, 20, 30])
print(a + b)  # Broadcasting happens here
```

## Reshaping
Why reshaping is important:
- Align dimensions for matrix operations.
- Prepare data for neural networks (e.g., flattening images).

The `reshape` function in NumPy and the `view` function in PyTorch are used to change the shape of an array or tensor without changing its data. The arguments to these functions specify the new shape.

- The new shape should be compatible with the original shape. This means that the total number of elements must remain the same.
- You can use `-1` as a placeholder for one of the dimensions, which means that dimension will be inferred based on the total number of elements.

Example of a 3x3 array being reshaped into a 1x9 array.

```python
a = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
print(a.reshape(-1))  # Flattening
```

In this example, `-1` tells NumPy to infer the size of the new dimension based on the total number of elements (which is 9 in this case), resulting in a 1x9 array.

Similarly, in PyTorch, you can use the `view` function to reshape a tensor.

```python
import torch

tensor = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
print(tensor.view(-1))  # Flattening
```
````

